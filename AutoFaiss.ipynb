{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ncu8GfzaYmE",
        "outputId": "3965b1ad-9dda-4576-b78f-264a68176ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gHOfyOMacgp",
        "outputId": "2d3e7b99-11f5-4e23-91ce-afca1280916f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 49 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 63.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845514 sha256=907c1182800e451771c09bc3e25e7f614c9cf26c120ce7c66d194987b48f73d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 13.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autofaiss\n",
            "  Downloading autofaiss-2.15.3-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: faiss-cpu<2,>=1.7.2 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (1.7.2)\n",
            "Collecting dataclasses<1.0.0,>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting fire<0.5.0,>=0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (4.64.1)\n",
            "Requirement already satisfied: pyarrow<8,>=6.0.1 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2022.1.0 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (2022.10.0)\n",
            "Requirement already satisfied: pandas<2,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (1.3.5)\n",
            "Requirement already satisfied: numpy<2,>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (1.21.6)\n",
            "Collecting embedding-reader<2,>=1.2.0\n",
            "  Downloading embedding_reader-1.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire<0.5.0,>=0.4.0->autofaiss) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<0.5.0,>=0.4.0->autofaiss) (2.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.5->autofaiss) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.5->autofaiss) (2.8.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115940 sha256=36463371263b8d6fadcda481fa91b4bbe9394969af954fcc455d7b4994ad11e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, embedding-reader, dataclasses, autofaiss\n",
            "Successfully installed autofaiss-2.15.3 dataclasses-0.6 embedding-reader-1.5.0 fire-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install faiss-cpu --no-cache\n",
        "!pip install autofaiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru7tpy_krFin"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odIpwutvq3TC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd3pxunWacqh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import faiss\n",
        "import glob\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from operator import add\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqIkbaarw8mH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsgu-1OIe-dc"
      },
      "source": [
        "dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5DxLMXeiCtC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "forest = fetch_covtype()\n",
        "Data= forest['data']\n",
        "label = forest['target']\n",
        "data_cov = np.concatenate([Data[:, :32], label.reshape(-1, 1)], axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw96SFCmidmU",
        "outputId": "17f6d2c6-b208-46d7-b9b8-631f23ad0787"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_cov = data_cov[:10000, :]\n",
        "data_cov.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWE8VXyHi7mk"
      },
      "outputs": [],
      "source": [
        "all_cov, query_cov = train_test_split(data_cov, test_size=0.2, random_state=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyfVZyREo9Lf"
      },
      "source": [
        "faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EX79ykBzroS"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"my_index_folder\", exist_ok=True)\n",
        "max_index_query_time_ms = 10 #@param {type: \"number\"}\n",
        "max_index_memory_usage = \"10MB\" #@param\n",
        "metric_type = \"l2\" #@param ['ip', 'l2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqnvWGsfqH3p"
      },
      "source": [
        "build index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4XBOFzZNDwm"
      },
      "outputs": [],
      "source": [
        "def build_index(all_data_np, query_data_np, dim, param, measure = faiss.METRIC_L2):\n",
        "\n",
        "    total_num = len(all_data_np)\n",
        "    total_index = []\n",
        "    for pi in range(10):\n",
        "        if pi < 9:\n",
        "            st, end = total_num // 10 * pi,  total_num // 10 * (pi + 1)\n",
        "        else:\n",
        "            st, end = total_num // 10 * pi,  total_num\n",
        "        index = faiss.index_factory(dim, param, measure)\n",
        "\n",
        "        xb = np.float32(all_data_np[st:end, :-1])\n",
        "        index.train(xb)\n",
        "        index.add(xb)\n",
        "        total_index.append(index)\n",
        "        \n",
        "    return total_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzaVjhFlzxhI"
      },
      "outputs": [],
      "source": [
        "def build_auto_index(all_data_np):\n",
        "    for pi in range(10):\n",
        "        embeddings_dir = \"tmp_folder\" + str(pi)\n",
        "        if os.path.exists(embeddings_dir):\n",
        "          shutil.rmtree(embeddings_dir)\n",
        "        os.makedirs(embeddings_dir)\n",
        "        knn_index = \"knn\" + str(pi) + \".index\"\n",
        "        infos_path = \"infos\" + str(pi) + \".json\"\n",
        "\n",
        "        total_num = len(all_data_np)\n",
        "        if pi < 9:\n",
        "            st, end = total_num // 10 * pi,  total_num // 10 * (pi + 1)\n",
        "        else:\n",
        "            st, end = total_num // 10 * pi,  total_num\n",
        "\n",
        "        print('all_data_np[st:end, :-1] = ', all_data_np[st:end, :-1].shape)\n",
        "        np.save(f\"{embeddings_dir}/emb.npy\", np.float32(all_data_np[st:end, :-1])) \n",
        "        !autofaiss build_index --embeddings={embeddings_dir} \\\n",
        "                            --index_path={knn_index} \\\n",
        "                            --index_infos_path={\"infos.json\"} \\\n",
        "                            --metric_type={metric_type} \\\n",
        "                            --max_index_query_time_ms=10 \\\n",
        "                            --max_index_memory_usage={max_index_memory_usage}\n",
        "def build_auto_index2():\n",
        "    total_index = []\n",
        "    for i in range(10):\n",
        "        total_index.append(faiss.read_index(\"knn\" + str(i) + \".index\"))\n",
        "    return total_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc1nj7WZ2_se"
      },
      "outputs": [],
      "source": [
        "def PQ_operation(all_data_np, query_data_np, K):\n",
        "    \n",
        "    def Distance_FAISS(test, train):\n",
        "        '''\n",
        "        Input:\n",
        "            - test: Numpy Array with label as last value\n",
        "            - train: Numpy Array with label as last value\n",
        "        \n",
        "        Returns distance between test and train arrays\n",
        "        '''\n",
        "        st = len(all_data_np) // 10* train[0]\n",
        "        distances, indices = total_index[train[0]].search(test[:-1].reshape(1, -1), K)\n",
        "        tmp = []\n",
        "        for i, (dist, indice) in enumerate(zip(distances[0], indices[0])):\n",
        "            tmp.append((dist, st + indice))\n",
        "        return tmp\n",
        "\n",
        "    spark = SparkSession\\\n",
        "            .builder\\\n",
        "            .appName(\"PythonKNN\")\\\n",
        "            .getOrCreate()\n",
        "\n",
        "    sc = spark.sparkContext\n",
        "    sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "    all_data = np.arange(10)\n",
        "    df = pd.DataFrame(all_data)\n",
        "    all_data = spark.createDataFrame(df)\n",
        "\n",
        "    df = pd.DataFrame(query_data_np)\n",
        "    query_data = spark.createDataFrame(df).rdd\n",
        "    query_data = query_data.map(lambda x: np.float32(x))\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    accuracy = 0\n",
        "    count = 0\n",
        "\n",
        "    for test_point in query_data.collect():\n",
        "\n",
        "        distances = all_data.rdd.map(\n",
        "            lambda train_point: Distance_FAISS(test_point, train_point))\n",
        "        \n",
        "        distances = sc.parallelize(distances.reduce(lambda a, b: a + b))\n",
        "        k_nearest_neighbours = sc.parallelize(distances.takeOrdered(K, key = lambda p: p[0])).map(lambda x: (all_data_np[x[1],-1], 1))\n",
        "        \n",
        "        k_nearest_predictions = k_nearest_neighbours.reduceByKey(\n",
        "            lambda x1, x2: x1 + x2)\n",
        "        \n",
        "        predict_label = k_nearest_predictions.takeOrdered(1,\n",
        "            key = lambda x: -x[1])[0][0]\n",
        "\n",
        "        if predict_label == test_point[-1]:\n",
        "            accuracy += 1\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print('accuracy = ', accuracy / count)\n",
        "    time_taken = end_time - start_time\n",
        "    print('time_taken = ', time_taken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXAar5uwn6Cy",
        "outputId": "b6b04b56-1da7-45b4-f16e-b2d3181153d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "all_cov.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgy5Cvcat2Mv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hhumItn1fX_",
        "outputId": "b35a65a2-ec4b-4c40-abfd-089c60ffcf57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_data_np[st:end, :-1] =  (800, 32)\n",
            "2022-11-15 19:32:48,549 [INFO]: Using 2 omp threads (processes), consider increasing --nb_cores if you have more\n",
            "2022-11-15 19:32:48,549 [INFO]: Launching the whole pipeline 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,549 [INFO]: Reading total number of vectors and dimension 11/15/2022, 19:32:48\n",
            "100% 1/1 [00:00<00:00, 24672.38it/s]\n",
            "2022-11-15 19:32:48,678 [INFO]: There are 800 embeddings of dim 32\n",
            "2022-11-15 19:32:48,678 [INFO]: >>> Finished \"Reading total number of vectors and dimension\" in 0.1291 secs\n",
            "2022-11-15 19:32:48,678 [INFO]: \tCompute estimated construction time of the index 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,678 [INFO]: \t\t-> Train: 16.7 minutes\n",
            "2022-11-15 19:32:48,678 [INFO]: \t\t-> Add: 0.0 seconds\n",
            "2022-11-15 19:32:48,678 [INFO]: \t\tTotal: 16.7 minutes\n",
            "2022-11-15 19:32:48,678 [INFO]: \t>>> Finished \"Compute estimated construction time of the index\" in 0.0002 secs\n",
            "2022-11-15 19:32:48,678 [INFO]: \tChecking that your have enough memory available to create the index 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,679 [INFO]: 110.0KB of memory will be needed to build the index (more might be used if you have more)\n",
            "2022-11-15 19:32:48,679 [INFO]: \t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0008 secs\n",
            "2022-11-15 19:32:48,679 [INFO]: \tSelecting most promising index types given data characteristics 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,679 [INFO]: \t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0000 secs\n",
            "2022-11-15 19:32:48,679 [INFO]: \tCreating the index 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,679 [INFO]: \t\t-> Instanciate the index Flat 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,680 [INFO]: \t\t>>> Finished \"-> Instanciate the index Flat\" in 0.0002 secs\n",
            "2022-11-15 19:32:48,680 [INFO]: \t\t-> Adding the vectors to the index 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,680 [INFO]: The memory available for adding the vectors is 32.0GB(total available - used by the index)\n",
            "2022-11-15 19:32:48,680 [INFO]: Using a batch size of 7812500 (memory overhead 953.7MB)\n",
            "100% 1/1 [00:00<00:00,  9.38it/s]\n",
            "2022-11-15 19:32:48,790 [INFO]: \tComputing best hyperparameters for index /content/knn0.index 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,790 [INFO]: \t>>> Finished \"Computing best hyperparameters for index /content/knn0.index\" in 0.0000 secs\n",
            "2022-11-15 19:32:48,790 [INFO]: The best hyperparameters are: \n",
            "2022-11-15 19:32:48,790 [INFO]: \tCompute fast metrics 11/15/2022, 19:32:48\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "2022-11-15 19:32:48,987 [INFO]: \t>>> Finished \"Compute fast metrics\" in 0.1965 secs\n",
            "2022-11-15 19:32:48,987 [INFO]: \tSaving the index on local disk 11/15/2022, 19:32:48\n",
            "2022-11-15 19:32:48,988 [INFO]: \t>>> Finished \"Saving the index on local disk\" in 0.0008 secs\n",
            "2022-11-15 19:32:48,988 [INFO]: \t\t>>> Finished \"-> Adding the vectors to the index\" in 0.3079 secs\n",
            "2022-11-15 19:32:48,988 [INFO]: {\n",
            "2022-11-15 19:32:48,988 [INFO]: \tindex_key: Flat\n",
            "2022-11-15 19:32:48,988 [INFO]: \tindex_param: \n",
            "2022-11-15 19:32:48,988 [INFO]: \tindex_path: /content/knn0.index\n",
            "2022-11-15 19:32:48,988 [INFO]: \tsize in bytes: 102445\n",
            "2022-11-15 19:32:48,988 [INFO]: \tavg_search_speed_ms: 0.034890497916642005\n",
            "2022-11-15 19:32:48,989 [INFO]: \t99p_search_speed_ms: 0.08117559997941688\n",
            "2022-11-15 19:32:48,989 [INFO]: \treconstruction error %: 0.0\n",
            "2022-11-15 19:32:48,989 [INFO]: \tnb vectors: 800\n",
            "2022-11-15 19:32:48,989 [INFO]: \tvectors dimension: 32\n",
            "2022-11-15 19:32:48,989 [INFO]: \tcompression ratio: 0.9995607399092196\n",
            "2022-11-15 19:32:48,989 [INFO]: }\n",
            "2022-11-15 19:32:48,989 [INFO]: \t>>> Finished \"Creating the index\" in 0.3096 secs\n",
            "2022-11-15 19:32:48,989 [INFO]: >>> Finished \"Launching the whole pipeline\" in 0.4403 secs\n",
            "(<faiss.swigfaiss.IndexFlat; proxy of <Swig Object of type 'faiss::IndexFlat *' at 0x7f2ab9953ea0> >, {'index_key': 'Flat', 'index_param': '', 'index_path': '/content/knn0.index', 'size in bytes': 102445, 'avg_search_speed_ms': 0.034890497916642005, '99p_search_speed_ms': 0.08117559997941688, 'reconstruction error %': 0.0, 'nb vectors': 800, 'vectors dimension': 32, 'compression ratio': 0.9995607399092196})\n",
            "all_data_np[st:end, :-1] =  (800, 32)\n",
            "2022-11-15 19:32:49,590 [INFO]: Using 2 omp threads (processes), consider increasing --nb_cores if you have more\n",
            "2022-11-15 19:32:49,591 [INFO]: Launching the whole pipeline 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,591 [INFO]: Reading total number of vectors and dimension 11/15/2022, 19:32:49\n",
            "100% 1/1 [00:00<00:00, 15650.39it/s]\n",
            "2022-11-15 19:32:49,716 [INFO]: There are 800 embeddings of dim 32\n",
            "2022-11-15 19:32:49,716 [INFO]: >>> Finished \"Reading total number of vectors and dimension\" in 0.1253 secs\n",
            "2022-11-15 19:32:49,716 [INFO]: \tCompute estimated construction time of the index 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,716 [INFO]: \t\t-> Train: 16.7 minutes\n",
            "2022-11-15 19:32:49,716 [INFO]: \t\t-> Add: 0.0 seconds\n",
            "2022-11-15 19:32:49,716 [INFO]: \t\tTotal: 16.7 minutes\n",
            "2022-11-15 19:32:49,716 [INFO]: \t>>> Finished \"Compute estimated construction time of the index\" in 0.0002 secs\n",
            "2022-11-15 19:32:49,716 [INFO]: \tChecking that your have enough memory available to create the index 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,717 [INFO]: 110.0KB of memory will be needed to build the index (more might be used if you have more)\n",
            "2022-11-15 19:32:49,717 [INFO]: \t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0008 secs\n",
            "2022-11-15 19:32:49,717 [INFO]: \tSelecting most promising index types given data characteristics 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,717 [INFO]: \t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0000 secs\n",
            "2022-11-15 19:32:49,718 [INFO]: \tCreating the index 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,718 [INFO]: \t\t-> Instanciate the index Flat 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,718 [INFO]: \t\t>>> Finished \"-> Instanciate the index Flat\" in 0.0002 secs\n",
            "2022-11-15 19:32:49,718 [INFO]: \t\t-> Adding the vectors to the index 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,718 [INFO]: The memory available for adding the vectors is 32.0GB(total available - used by the index)\n",
            "2022-11-15 19:32:49,718 [INFO]: Using a batch size of 7812500 (memory overhead 953.7MB)\n",
            "100% 1/1 [00:00<00:00,  9.26it/s]\n",
            "2022-11-15 19:32:49,829 [INFO]: \tComputing best hyperparameters for index /content/knn1.index 11/15/2022, 19:32:49\n",
            "2022-11-15 19:32:49,830 [INFO]: \t>>> Finished \"Computing best hyperparameters for index /content/knn1.index\" in 0.0000 secs\n",
            "2022-11-15 19:32:49,830 [INFO]: The best hyperparameters are: \n",
            "2022-11-15 19:32:49,830 [INFO]: \tCompute fast metrics 11/15/2022, 19:32:49\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "2022-11-15 19:32:50,017 [INFO]: \t>>> Finished \"Compute fast metrics\" in 0.1873 secs\n",
            "2022-11-15 19:32:50,017 [INFO]: \tSaving the index on local disk 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,018 [INFO]: \t>>> Finished \"Saving the index on local disk\" in 0.0008 secs\n",
            "2022-11-15 19:32:50,018 [INFO]: \t\t>>> Finished \"-> Adding the vectors to the index\" in 0.3002 secs\n",
            "2022-11-15 19:32:50,018 [INFO]: {\n",
            "2022-11-15 19:32:50,019 [INFO]: \tindex_key: Flat\n",
            "2022-11-15 19:32:50,019 [INFO]: \tindex_param: \n",
            "2022-11-15 19:32:50,019 [INFO]: \tindex_path: /content/knn1.index\n",
            "2022-11-15 19:32:50,019 [INFO]: \tsize in bytes: 102445\n",
            "2022-11-15 19:32:50,019 [INFO]: \tavg_search_speed_ms: 0.03104659541627086\n",
            "2022-11-15 19:32:50,019 [INFO]: \t99p_search_speed_ms: 0.047944489983251196\n",
            "2022-11-15 19:32:50,019 [INFO]: \treconstruction error %: 0.0\n",
            "2022-11-15 19:32:50,019 [INFO]: \tnb vectors: 800\n",
            "2022-11-15 19:32:50,019 [INFO]: \tvectors dimension: 32\n",
            "2022-11-15 19:32:50,019 [INFO]: \tcompression ratio: 0.9995607399092196\n",
            "2022-11-15 19:32:50,019 [INFO]: }\n",
            "2022-11-15 19:32:50,019 [INFO]: \t>>> Finished \"Creating the index\" in 0.3013 secs\n",
            "2022-11-15 19:32:50,019 [INFO]: >>> Finished \"Launching the whole pipeline\" in 0.4286 secs\n",
            "(<faiss.swigfaiss.IndexFlat; proxy of <Swig Object of type 'faiss::IndexFlat *' at 0x7f9d35c6eea0> >, {'index_key': 'Flat', 'index_param': '', 'index_path': '/content/knn1.index', 'size in bytes': 102445, 'avg_search_speed_ms': 0.03104659541627086, '99p_search_speed_ms': 0.047944489983251196, 'reconstruction error %': 0.0, 'nb vectors': 800, 'vectors dimension': 32, 'compression ratio': 0.9995607399092196})\n",
            "all_data_np[st:end, :-1] =  (800, 32)\n",
            "2022-11-15 19:32:50,622 [INFO]: Using 2 omp threads (processes), consider increasing --nb_cores if you have more\n",
            "2022-11-15 19:32:50,622 [INFO]: Launching the whole pipeline 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,622 [INFO]: Reading total number of vectors and dimension 11/15/2022, 19:32:50\n",
            "100% 1/1 [00:00<00:00, 21732.15it/s]\n",
            "2022-11-15 19:32:50,748 [INFO]: There are 800 embeddings of dim 32\n",
            "2022-11-15 19:32:50,748 [INFO]: >>> Finished \"Reading total number of vectors and dimension\" in 0.1255 secs\n",
            "2022-11-15 19:32:50,748 [INFO]: \tCompute estimated construction time of the index 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,748 [INFO]: \t\t-> Train: 16.7 minutes\n",
            "2022-11-15 19:32:50,748 [INFO]: \t\t-> Add: 0.0 seconds\n",
            "2022-11-15 19:32:50,748 [INFO]: \t\tTotal: 16.7 minutes\n",
            "2022-11-15 19:32:50,748 [INFO]: \t>>> Finished \"Compute estimated construction time of the index\" in 0.0002 secs\n",
            "2022-11-15 19:32:50,748 [INFO]: \tChecking that your have enough memory available to create the index 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,749 [INFO]: 110.0KB of memory will be needed to build the index (more might be used if you have more)\n",
            "2022-11-15 19:32:50,749 [INFO]: \t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0007 secs\n",
            "2022-11-15 19:32:50,749 [INFO]: \tSelecting most promising index types given data characteristics 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,749 [INFO]: \t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0000 secs\n",
            "2022-11-15 19:32:50,749 [INFO]: \tCreating the index 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,749 [INFO]: \t\t-> Instanciate the index Flat 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,750 [INFO]: \t\t>>> Finished \"-> Instanciate the index Flat\" in 0.0003 secs\n",
            "2022-11-15 19:32:50,750 [INFO]: \t\t-> Adding the vectors to the index 11/15/2022, 19:32:50\n",
            "2022-11-15 19:32:50,750 [INFO]: The memory available for adding the vectors is 32.0GB(total available - used by the index)\n",
            "2022-11-15 19:32:50,750 [INFO]: Using a batch size of 7812500 (memory overhead 953.7MB)\n",
            "  0% 0/1 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "build_auto_index(all_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0KHD_ZdBWUT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g5xOk6L3OsB",
        "outputId": "5e15f045-2aea-41ab-934a-d164d0f7f857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.772\n",
            "time_taken =  664.60009932518\n",
            "accuracy =  0.758\n",
            "time_taken =  622.645307302475\n",
            "accuracy =  0.7275\n",
            "time_taken =  611.6613938808441\n",
            "accuracy =  0.692\n",
            "time_taken =  612.2968657016754\n"
          ]
        }
      ],
      "source": [
        "dim, measure, param = all_cov.shape[1]-1, faiss.METRIC_L2, 'PQ4'\n",
        "total_index = build_index(all_cov, query_cov, dim, param, measure = faiss.METRIC_L2)\n",
        "for k in [8, 16,32,64]:\n",
        "    PQ_operation(all_cov, query_cov, k // 2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}