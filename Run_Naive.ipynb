{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ncu8GfzaYmE",
        "outputId": "890bea27-d35d-4a2e-f25a-38d36f7534d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gHOfyOMacgp",
        "outputId": "9b25f9d9-0fcd-448b-82a8-00aeb652575f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 49.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845514 sha256=67a9634a3c93158a86516e00fd9ce594d16ba4d722a6d576fbf1072e0866f515\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autofaiss\n",
            "  Downloading autofaiss-2.15.3-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (1.3.5)\n",
            "Collecting fire<0.5.0,>=0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: faiss-cpu<2,>=1.7.2 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (1.7.2)\n",
            "Collecting dataclasses<1.0.0,>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting embedding-reader<2,>=1.2.0\n",
            "  Downloading embedding_reader-1.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (4.64.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (1.21.6)\n",
            "Requirement already satisfied: pyarrow<8,>=6.0.1 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2022.1.0 in /usr/local/lib/python3.7/dist-packages (from autofaiss) (2022.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire<0.5.0,>=0.4.0->autofaiss) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<0.5.0,>=0.4.0->autofaiss) (2.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.5->autofaiss) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.5->autofaiss) (2.8.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115940 sha256=a1568878834dcc860709689d13855814eb4926f7d2e48502a434e5467beaa602\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, embedding-reader, dataclasses, autofaiss\n",
            "Successfully installed autofaiss-2.15.3 dataclasses-0.6 embedding-reader-1.5.0 fire-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install faiss-cpu --no-cache\n",
        "!pip install autofaiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru7tpy_krFin"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odIpwutvq3TC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd3pxunWacqh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import faiss\n",
        "import glob\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from operator import add\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqIkbaarw8mH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsgu-1OIe-dc"
      },
      "source": [
        "dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5DxLMXeiCtC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "forest = fetch_covtype()\n",
        "Data= forest['data']\n",
        "label = forest['target']\n",
        "data_cov = np.concatenate([Data[:, :32], label.reshape(-1, 1)], axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw96SFCmidmU",
        "outputId": "de16c6a8-1477-49ee-dd50-3a3cf60493f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data_cov = data_cov[:10000, :]\n",
        "data_cov.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWE8VXyHi7mk"
      },
      "outputs": [],
      "source": [
        "all_cov, query_cov = train_test_split(data_cov, test_size=0.2, random_state=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R0Wltz-idpG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsjASKSdiCv8"
      },
      "outputs": [],
      "source": [
        "# from keras.datasets import mnist\n",
        "# (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "# data_p1 = np.concatenate([train_X.reshape(-1, 28 * 28), train_y.reshape(-1, 1)], axis = -1)\n",
        "# data_p2 = np.concatenate([test_X.reshape(-1, 28 * 28), test_y.reshape(-1, 1)], axis = -1)\n",
        "# data_mnist = np.concatenate([data_p1, data_p2], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zrtPMeiftF3"
      },
      "outputs": [],
      "source": [
        "# data_mnist = data_mnist[:10000, :]\n",
        "# data_mnist.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srtAKnEAi-fp"
      },
      "outputs": [],
      "source": [
        "# all_mnt, query_mnt = train_test_split(data_mnist, test_size=0.2, random_state=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lop4HCUwi-9g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7D-Ydjbg8yA"
      },
      "source": [
        "naive baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoMstdJMg-nK"
      },
      "outputs": [],
      "source": [
        "def calculateDistance(test_point, train_point, p=2):\n",
        "    # minkowski distance\n",
        "    # p = 2 --> euclidean distance\n",
        "    \n",
        "    dist = np.sum((test_point[:-1]-train_point[:-1])**p)\n",
        "    dist = dist**(1/p)\n",
        "    return dist\n",
        "\n",
        "def calculateDistance2(test_point,train_point):\n",
        "    # Euclidean distance\n",
        "    dist = np.sqrt(np.sum((test_point-train_point)**2))\n",
        "    return dist\n",
        "\n",
        "def origKNN(train_x, test_x, k, p=2):\n",
        "    \n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    train_y = train_x[:, -1].copy()\n",
        "    test_y = test_x[:, -1].copy()\n",
        "\n",
        "    predList = []\n",
        "    count_ = 0\n",
        "    for test_point in test_x:\n",
        "        distList = []\n",
        "        for train_point in train_x:\n",
        "            distance = calculateDistance(test_point,train_point, p)\n",
        "            distList.append((distance, train_point[-1]))\n",
        "        distList = sorted(distList)[:k]\n",
        "        tmp = []\n",
        "        for dis, label in distList:\n",
        "          tmp.append(label)\n",
        "        count = Counter(tmp)\n",
        "        finalPrediction = count.most_common(1)[0][0]\n",
        "        predList.append(finalPrediction) \n",
        "        count_ += 1\n",
        "        if count_ % 1000 == 0: print('count_ = ', count_)\n",
        "      \n",
        "    print('count_ = ', count_)\n",
        "    end = time.time()\n",
        "\n",
        "    print(\"Original KNN running time: {}\".format(end-start))\n",
        "    print(accuracy_score(test_y, predList))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4x2hqkCg-qG",
        "outputId": "e1f0fd27-75bd-4d2e-99fd-a380b09525a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count_ =  1000\n",
            "count_ =  2000\n",
            "count_ =  2000\n",
            "Original KNN running time: 173.9551968574524\n",
            "0.7785\n",
            "count_ =  1000\n",
            "count_ =  2000\n",
            "count_ =  2000\n",
            "Original KNN running time: 175.52844309806824\n",
            "0.747\n",
            "count_ =  1000\n",
            "count_ =  2000\n",
            "count_ =  2000\n",
            "Original KNN running time: 174.9058539867401\n",
            "0.7115\n",
            "count_ =  1000\n",
            "count_ =  2000\n",
            "count_ =  2000\n",
            "Original KNN running time: 174.92647242546082\n",
            "0.6535\n"
          ]
        }
      ],
      "source": [
        "for k in [8, 16, 32, 64]:\n",
        "  origKNN(all_cov, query_cov, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBa_hQbZg-1Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}